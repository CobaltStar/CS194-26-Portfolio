# -*- coding: utf-8 -*-
"""Training_Kaggle.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ATDGkDVqKhAHZZGNrYl9LJgjtWG6kyom
"""



from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt

import skimage as sk
import skimage.io as skio
from skimage.transform import resize
from sklearn.model_selection import train_test_split
from skimage.color import rgb2gray
from skimage import data

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision
from torchvision import transforms, utils
import math

import matplotlib.patches as patches
import random
import xml.etree.ElementTree as ET
import os
from tqdm import tqdm

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Using {} device'.format(device))

data_set_path = "/content/drive/MyDrive/Colab Notebooks/ibug_300W_large_face_landmark_dataset"

tree = ET.parse(data_set_path + '/labels_ibug_300W_train.xml')  
root = tree.getroot()
root_dir = '/content/drive/MyDrive/Colab Notebooks/ibug_300W_large_face_landmark_dataset'

face_boxes = [] 
img_filenames = []
landmark_set = []

for filename in root[2]:
  box = filename[0].attrib
  img_filenames.append(os.path.join(root_dir, filename.attrib['file']))

  box = filename[0].attrib
  # add corners with some extra padding
  new_w = int(float(box['width']) * 1.2)
  new_h = int(float(box['height'])* 1.2)
  diff_x = int((new_w - float(box['width']))/2)
  diff_y = int((new_h - float(box['height']))/2)

  face_boxes.append([float(box['left']) - diff_x, float(box['top']) - diff_y, new_w, new_h])

  # populate landmark_set
  landmarks = []
  for num in range(68):
    x_coords = int(filename[0][num].attrib['x'])
    y_coords = int(filename[0][num].attrib['y'])
    landmarks.append([x_coords, y_coords])
  landmark_set.append(landmarks)

landmark_set = np.array(landmark_set).astype('float32')   
face_boxes = np.array(face_boxes).astype('float32')

"""# Data Loading"""

from torch.utils.data import Dataset, DataLoader

def crop_img(im, box):
  # Make sure crop indices don't go out of bounds
  # for ind in box:
  
  if box[0] < 0:
    box[2] = box[2] + box[0]
    box[0] = 0
  if box[1] < 0:
    box[3] = box[3] + box[1]
    box[1] = 0
  if box[1] + box[3] > im.shape[0]:
    box[3] = im.shape[0] - box[1]
  if box[0] + box[2] > im.shape[1]:
    box[2] = im.shape[1] - box[0]
  box[3] = min(box[3], im.shape[0])
  box[2] = min(box[2], im.shape[1])
  # Crop
  im = im[box[1]:box[1]+box[3],box[0]:box[0]+box[2]]
  return im

def resize_img(im, resize_dim):
  im = resize(im, (resize_dim, resize_dim))
  return im

def crop_resize_landmarks(landmarks, box, resize_dim, imshape):
  xs = landmarks[:, 0] - box[0]
  ys = landmarks[:, 1] - box[1]

  # resize points
  scalar = resize_dim * 1.0 / imshape[0]
  xs = xs * scalar
  ys = ys * scalar
  return xs, ys

def show_im_w_pts(im, landmarks):
  plt.scatter(landmarks[:, 0], landmarks[:, 1], c='blue')
  plt.imshow(im, cmap='gray')

def save_im_w_pts(im, landmarks, fname, extra_landmarks=None):
  plt.scatter(landmarks[:, 0], landmarks[:, 1],c='red')
  if extra_landmarks is not None:
    plt.scatter(extra_landmarks[:, 0], extra_landmarks[:, 1],c='green')
  plt.imshow(im, cmap='gray')
  plt.savefig(fname)
  plt.close()

# image_list = []
# for i in range(len(img_filenames)):
#   # image_list.append(sk.color.rgb2gray(skio.imread(img_filenames[i])))
#   image_list.append(skio.imread(img_filenames[i], as_gray=True))

import imgaug as ia
import imgaug.augmenters as iaa
from imgaug.augmentables import Keypoint, KeypointsOnImage

class LandmarkDataset(Dataset):
  def __init__(self, start_index, end_index, images_name_set, landmarks_set, face_boxes, image_dimensions=244, augment=False):   
    self.image_dimensions = image_dimensions

    self.images_name_set = images_name_set[start_index: end_index]
    self.landmarks_set = landmarks_set[start_index: end_index]
    self.face_boxes = face_boxes[start_index: end_index]

    self.augment = augment

    if augment:
      self.jitter = transforms.ColorJitter(brightness = .5, contrast=.5, saturation=.5, hue=.2)

  def __getitem__(self, i):
    if torch.is_tensor(i):
            i = i.tolist()
    landmark = np.copy(self.landmarks_set[i])
    image = sk.color.rgb2gray(skio.imread(self.images_name_set[i]))
    box = self.face_boxes[i].astype(int)

    # Crop
    image = crop_img(image, box)

    # Resize
    landmark[:, 0], landmark[:, 1] = crop_resize_landmarks(landmark, box, self.image_dimensions, image.shape)
    image = resize_img(image, self.image_dimensions)

    sample = {'image': image.astype('float32'), 'landmarks': landmark.astype('float32')}
    if self.augment:
      sample = self.augment_transform(sample)

    return sample

  def __len__(self):
    return len(self.landmarks_set)

  def augment_transform(self, sample):
    # Source: https://imgaug.readthedocs.io/en/latest/source/examples_basics.html

    # Set random transfrom params and define transform function
    img, landmarks = sample['image'], sample['landmarks']

    # Multiply Blending
    to_multiply = random.random() + 0.5
    
    # Sometimes function to drop out (tear holes in)
    sometimes = lambda aug: iaa.Sometimes(0.5, aug)

    seq = iaa.Sequential([
        iaa.Multiply(to_multiply),
        iaa.LinearContrast((0.75, 1.5)),
        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05)),
        sometimes(iaa.Crop(percent=(0, 0.1))),
        # Scale/zoom, translate/move, rotate, shear      
        iaa.Affine(
            scale={"x": (0.8, 1.2), "y": (0.8, 1.2)},
            translate_percent={"x": (-0.2, 0.2), "y": (-0.2, 0.2)},
            rotate=(-25, 25),
            shear=(-8, 8)
        ),
        sometimes(iaa.OneOf([
                    iaa.Dropout((0.01, 0.1), per_channel=0.5),
                    iaa.CoarseDropout(
                        (0.03, 0.15), size_percent=(0.02, 0.05),
                        per_channel=0.2
                    ),
                ])),
    ])
    # Set keypoints to transform
    keypoints = KeypointsOnImage([Keypoint(x=keypt[0],y=keypt[1]) for keypt in landmarks], shape = img.shape)
    im_aug, landmarks_aug = seq(image=img.astype(float), keypoints=keypoints)
    landmarks = np.array([[keypt.x, keypt.y] for keypt in landmarks_aug.keypoints])
    return {'image': im_aug, 'landmarks': landmarks}

train_dataset = LandmarkDataset(0, 6000, img_filenames, landmark_set, face_boxes, augment=True) # imgs 0-5999
print("loaded training set")
print(len(train_dataset))
validation_dataset = LandmarkDataset(6000, 6665, img_filenames, landmark_set, face_boxes, augment=False) # imgs 6000-6665
print("loaded validation set")
print(len(validation_dataset))
# test_dataset = TestDataset()
# print("loaded test data set")

sample = train_dataset.__getitem__(630)
im = sample['image']
keypts = sample['landmarks']
show_im_w_pts(im, keypts)
plt.scatter(keypts[:, 0], keypts[:, 1], c='red')
plt.imshow(im, cmap='gray')

"""# Training"""

def train(dataloader, model, loss_function, optimizer):
    size = len(dataloader.dataset)
    model.train()
    
    total_loss = 0
    
    for i, batch in tqdm(enumerate(dataloader)):
        if (i % 100 == 0):
          print("processed another 100 batches")
        image, keypoint = batch['image'], batch['landmarks']
        # image = image.unsqueeze(0)
        image = image.float().unsqueeze(1)

        image, keypoint = image.to(device), keypoint.to(device)
        
        # Zero your gradients for every batch!
        model.zero_grad()
        # Make predictions for this batch
        output = model(image)
        output = output.flatten()
        keypoint = keypoint.flatten()
        loss = loss_function(output, keypoint)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()

        del image
        del keypoint
        torch.cuda.empty_cache()
        
    mean_loss = total_loss / (i + 1)
        
    return mean_loss

def validate(dataloader, model, loss_function, optimizer):
    size = len(dataloader.dataset)
    model.eval()
    
    total_loss = 0
    
    for i, batch in tqdm(enumerate(dataloader)):
        image, keypoint = batch['image'], batch['landmarks']
        # image = image.unsqueeze(0)
        image = image.float().unsqueeze(1)
        image, keypoint = image.to(device), keypoint.to(device)
        
        # Zero your gradients for every batch!
        model.zero_grad()
        # Make predictions for this batch
        output = model(image)
        output = output.flatten()
        keypoint = keypoint.flatten()

        loss = loss_function(output, keypoint)     
        total_loss += loss.item()

        del image
        del keypoint
        torch.cuda.empty_cache()
        
    mean_loss = total_loss / (i + 1)
        
    return mean_loss

def predict(dataloader, model):
    outputs = []
    model.eval()
    
    for batch in dataloader:
        image = batch['image']
        image = image.float().unsqueeze(1)
        image = image.to(device)
        
        output = model(image)

        output = output.cpu()
        outputs.append(output.detach().numpy())

        del image
    
    output_vector = np.stack(outputs, axis=0)
    return output_vector

BATCH_SIZE = 128
NUM_WORKERS = 2
NUM_EPOCHS = 15

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)

import torchvision.models as models
model = models.resnet18(pretrained=True)
model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7,7), stride=(2,2), padding=(2,2), bias=False)
model.fc = torch.nn.Linear(512 * model.layer1[0].expansion, 136)
# model = model.float()
model = model.to(device, dtype=torch.float)

# Loss function
loss_fn = torch.nn.MSELoss()

# Optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # learning rate=1e-3

torch.nn.Linear(512 * model.layer1[0].expansion, 136)

train_losses = []
val_losses = []
import time

for epoch in range(NUM_EPOCHS):
    train_loss = train(train_loader, model, loss_fn, optimizer)
    print("Epoch Training Loss:", train_loss)
    torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/models/model'+time.strftime('%H%M%S')+'.pt')  
    val_loss = validate(val_loader, model, loss_fn, optimizer)
    print("Epoch Validation Loss:", val_loss)  
    train_losses.append(train_loss)
    val_losses.append(val_loss)

    print("finished epoch: ", epoch)

train_losses

val_losses

train_losses = [16912.487200797874,
                9921.070624168882,
                5071.137736868351,
                2394.319876163564,
                1374.3398411527594,
                1068.0849050968252,
                931.0446556578291,
                788.5899242644614,
                657.2046443858045,
                563.9719777208694,
                507.57640108149104,
                457.0535674399518,
                382.17111335916724,
                278.1155155263049,
                223.55444822920128,
                203.30848206865028,
                187.73126285634143]

val_losses = [11610.314127604166,
              6512.843668619792,
              2726.730997721354,
              844.8290303548177,
              452.859135945638,
              279.5690409342448,
              257.27233632405597,
              357.0324350992839,
              219.48041534423828,
              202.8890177408854,
              205.31771341959634,
              175.07744598388672,
              145.66884104410806,
              133.22111129760742,
              197.55113220214844,
              138.6497014363607,
              158.5707753499349]

plt.figure(figsize = (10, 7))
plt.plot(range(len(train_losses)), train_losses, label = 'training loss')
plt.plot(range(len(val_losses)), val_losses, label = 'validation loss')
plt.ylabel('MSE')
plt.xlabel('epoch')
plt.title('train and val loss over epochs for facial network')
plt.legend()
plt.savefig("more_points_train_val_loss.jpg")

"""Predict"""

im = validation_dataset[70]["image"]
keypts = y_predict[70].reshape((68, 2))
show_im_w_pts(im, keypts)
print(keypts)
print(len(keypts[0]))

data_set_path = "/content/drive/MyDrive/Colab Notebooks/ibug_300W_large_face_landmark_dataset"
tree = ET.parse(data_set_path +'/labels_ibug_300W_test_parsed.xml')
root = tree.getroot()
root_dir = '/content/drive/MyDrive/Colab Notebooks/ibug_300W_large_face_landmark_dataset'

# data_set_path = "/content/drive/MyDrive/Colab Notebooks/ibug_300W_large_face_landmark_dataset"

# tree = ET.parse(data_set_path + '/labels_ibug_300W_train.xml')  
# root = tree.getroot()
# root_dir = '/content/drive/MyDrive/Colab Notebooks/ibug_300W_large_face_landmark_dataset'

face_boxes_test = [] 
img_filenames_test = [] 

for filename in root[2]:
  img_filenames_test.append(os.path.join(root_dir, filename.attrib['file']))
  box = filename[0].attrib
  new_w = int(float(box['width']) * 1.2)
  new_h = int(float(box['height'])* 1.2)
  diff_x = int((new_w - float(box['width']))/2)
  diff_y = int((new_h - float(box['height']))/2)
  face_boxes_test.append([float(box['left'])-diff_x, float(box['top'])-diff_y, new_w, new_h]) 
face_boxes_test = np.array(face_boxes_test).astype('float32')

class TestDataset(Dataset):
  def __init__(self, images_name_set, face_boxes, image_dimensions=244):   
    self.image_dimensions = image_dimensions

    self.images_name_set = images_name_set
    self.face_boxes = face_boxes

  def __getitem__(self, i):
    if torch.is_tensor(i):
            i = i.tolist()

    image = sk.color.rgb2gray(skio.imread(self.images_name_set[i]))
    box = self.face_boxes[i].astype(int)

    # Crop
    image = crop_img(image, box)

    # Resize
    image = resize_img(image, self.image_dimensions)

    return image

  def __len__(self):
    return len(self.images_name_set)

def predict(dataloader, model):
    outputs = []
    model.eval()
    
    for batch in dataloader:
        image = batch
        image = image.float().unsqueeze(1)
        image = image.to(device)
        
        output = model(image)

        output = output.cpu()
        outputs.append(output.detach().numpy().reshape((68, 2)))

        del image
    
    output_vector = np.stack(outputs, axis=0)
    return output_vector

NUM_WORKERS = 2
test_dataset = TestDataset(img_filenames_test, face_boxes_test)
test_loader = DataLoader(test_dataset, batch_size=1, num_workers=NUM_WORKERS)

test_predict = predict(test_loader, model)
torch.save(test_predict, 'test_predict.pt')

test_predict = torch.load("/content/test_predict.pt")

im = test_dataset[70]
keypts = test_predict[70]
show_im_w_pts(im, keypts)
plt.savefig("TestPrediction1.jpg")
keypts.shape

im = test_dataset[69]
keypts = test_predict[69]
show_im_w_pts(im, keypts)
plt.savefig("TestPrediction2.jpg")

def get_original_image_w_pts(keypoint_set, dataset, dataset_ind, im_filenames_lst, boxes_lst):
  im_ind = dataset_ind
  im = sk.color.rgb2gray(skio.imread(im_filenames_lst[im_ind]))
  box = boxes_lst[im_ind].astype(int)
  keypoints = np.copy(keypoint_set[dataset_ind])
  ret_pts = np.copy(keypoint_set[dataset_ind])
  # / dataset.image_dimensions
  ret_pts[:,0] = (keypoints[:,0] / dataset.image_dimensions)*box[2] + box[0]
  ret_pts[:,1] = (keypoints[:,1] / dataset.image_dimensions)*box[3] + box[1]
  return im, ret_pts

a, b = get_original_image_w_pts(test_predict, test_dataset, 0, img_filenames_test, face_boxes_test)
show_im_w_pts(a, b)
plt.savefig("TestPrediction3.jpg")

"""# Saving to CSV"""

def get_original_pts(keypoint_set, dataset, dataset_ind, im_filenames_lst, boxes_lst):
  box = boxes_lst[dataset_ind].astype(int)
  keypoints = np.copy(keypoint_set[dataset_ind])
  ret_pts = np.copy(keypoint_set[dataset_ind])
  # / dataset.image_dimensions
  ret_pts[:,0] = (keypoints[:,0] / dataset.image_dimensions)*box[2] + box[0]
  ret_pts[:,1] = (keypoints[:,1] / dataset.image_dimensions)*box[3] + box[1]
  return ret_pts

def to_csv(keypoints_lst, fname="/content/predictions.csv"):
  ids = np.arange(len(keypoints_lst))
  csv_array = np.zeros((len(keypoints_lst), 2))
  csv_array[:,0] = ids.astype(int)
  csv_array[:,1] = keypoints_lst
  np.savetxt(fname, csv_array, delimiter=',')

test_keypt_predictions_formatted = []

for i, keypoints in enumerate(test_predict):
  keypoints = get_original_pts(test_predict, test_dataset, i, img_filenames_test, face_boxes_test)

  for point in keypoints:
    test_keypt_predictions_formatted.append(point[0])
    test_keypt_predictions_formatted.append(point[1])

print(len(test_keypt_predictions_formatted))
to_csv(test_keypt_predictions_formatted)

import csv
with open('/content/predictions.csv',newline='') as f:
    r = csv.reader(f)
    data = [line for line in r]

"""# Try my own photos"""

